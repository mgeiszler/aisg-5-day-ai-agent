{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get repsonse from an LLM\n",
    "\n",
    "\n",
    "To get started, [get an API key](https://g.co/ai/idxGetGeminiKey) and replace the word `API KEY` below with your API key:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build your own Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter User Query?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To answer this question, I need to know the current weather conditions.  I'll start by getting the user's location to make the weather report more relevant.\n",
      "\n",
      "Action: getLocation: null\n",
      "PAUSE\n",
      "\n",
      "Call 1:\n",
      "Thought: To answer this question, I need to know the current weather conditions.  I'll start by getting the user's location to make the weather report more relevant.\n",
      "\n",
      "Action: getLocation: null\n",
      "PAUSE\n",
      "\n",
      "Call 2:\n",
      "Thought: To answer this question, I need to know the current weather conditions.  I'll start by getting the user's location to make the weather report more relevant.\n",
      "\n",
      "Action: getLocation: null\n",
      "PAUSE\n",
      "\n",
      "Call 3:\n",
      "Thought: To answer this question, I need to know the current weather conditions.  I'll start by getting the user's location to make the weather report more relevant.\n",
      "\n",
      "Action: getLocation: null\n",
      "PAUSE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access the API key from the environment variable\n",
    "api_key = os.getenv(\"SECRET_KEY\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "prompt = \"\"\"\n",
    "You cycle through Thought, Action, PAUSE, Observation. At the end of the loop you output a final Answer. Your final answer should be highly specific to the observations you have from running\n",
    "the actions.\n",
    "1. Thought: Describe your thoughts about the question you have been asked.\n",
    "2. Action: run one of the actions available to you - then return PAUSE.\n",
    "3. PAUSE\n",
    "4. Observation: will be the result of running those actions.\n",
    "\n",
    "Available actions:\n",
    "- getCurrentWeather: \n",
    "    E.g. getCurrentWeather: Salt Lake City\n",
    "    Returns the current weather of the location specified.\n",
    "- getLocation:\n",
    "    E.g. getLocation: null\n",
    "    Returns user's location details. No arguments needed.\n",
    "\n",
    "Example session:\n",
    "Question: Please give me some ideas for activities to do this afternoon.\n",
    "Thought: I should look up the user's location so I can give location-specific activity ideas.\n",
    "Action: getLocation: null\n",
    "PAUSE\n",
    "\n",
    "You will be called again with something like this:\n",
    "Observation: \"New York City, NY\"\n",
    "\n",
    "Then you loop again:\n",
    "Thought: To get even more specific activity ideas, I should get the current weather at the user's location.\n",
    "Action: getCurrentWeather: New York City\n",
    "PAUSE\n",
    "\n",
    "You'll then be called again with something like this:\n",
    "Observation: { location: \"New York City, NY\", forecast: [\"sunny\"] }\n",
    "\n",
    "You then output:\n",
    "Answer: <Suggested activities based on sunny weather that are highly specific to New York City and surrounding areas.>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"Enter User Query?\")\n",
    "query = input()\n",
    "\n",
    "# Combine the system prompt and user query into a single input because gemini does not take messages arrays like GPT!\n",
    "full_prompt = f\"{prompt}\\n\\nUser: {query}\\nAssistant:\"\n",
    "response = model.generate_content(full_prompt)\n",
    "print(response.parts[0].text)\n",
    "\n",
    "\n",
    "\n",
    "# Define your query\n",
    "query = \"How do I use discord to find pinned messages?\"\n",
    "\n",
    "max_calls = 3\n",
    "action_regex = r\"^Action: (\\w+): (.*)$\"\n",
    "\n",
    "# call the llm atleast 3 times \n",
    "for i in range(max_calls):\n",
    "    print(f\"Call {i + 1}:\")\n",
    "\n",
    "    # Split response text into lines\n",
    "    response_lines = response.text.strip().split(\"\\n\")\n",
    "\n",
    "    # Find the action string in the response\n",
    "    found_action_str = next((line for line in response_lines if re.match(action_regex, line)), None)\n",
    "\n",
    "    # Dummy functions to simulate API calls\n",
    "    def getLocation(place=None):\n",
    "        location = {\n",
    "            \"city\": \"New York City\",\n",
    "            \"state\": \"NY\",\n",
    "            \"country\": \"USA\"\n",
    "        }\n",
    "        return location\n",
    "\n",
    "    def getCurrentWeather(place=None):\n",
    "        weather = {\n",
    "            \"temperature\": \"2\",\n",
    "            \"unit\": \"F\",\n",
    "            \"forecast\": \"snowy\"\n",
    "        }\n",
    "        return weather\n",
    "\n",
    "    # Map available functions\n",
    "    available_functions = {\n",
    "        \"getLocation\": getLocation,\n",
    "        \"getCurrentWeather\": getCurrentWeather\n",
    "    }\n",
    "\n",
    "    # Execute the identified action if it matches\n",
    "    actions = re.match(action_regex, found_action_str) if found_action_str else None\n",
    "    if actions:\n",
    "        action, action_arg = actions.groups()\n",
    "        if action in available_functions:\n",
    "            observation = available_functions[action](action_arg)\n",
    "            print(response.text)\n",
    "        else:\n",
    "            print(f\"Action '{action}' is not available.\")\n",
    "    else:\n",
    "        print(\"No valid action found.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg-aisg-5-day-ai-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
